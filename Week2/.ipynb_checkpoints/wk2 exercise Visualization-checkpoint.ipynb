{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*week 2 exercise - part 1*\n",
    "\n",
    "# Basic Charts with Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matplotlib\n",
    "\n",
    "First, we import the required libraries, using standard conventions. We first import numpy for all our mathematical needs, then the matplotlib as plotting library and pyplot which gives an easy API to create plots with matplotlib. Later we will introduce Seaborn as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# we need the following line to indicate that the plots should be shown inline with the Jupyter notebook.\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first create a simple plot of a mathematical function. We first create a numpy array of x-values. Then for each x-value we create the y-value, i.e. the function value. Plotting this function is as easy as giving it the x and y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-np.pi, np.pi, 100) # define a NumPy array with 100 points in the range -Pi to Pi\n",
    "Y = np.sin(X)  # define the curve Y by the sine of X\n",
    "\n",
    "plt.plot(X,Y); # use matplotlib to plot the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While creating such plots is perfectly fine when you are exploring data, in your final notebook the plot is hard to understand for the reader. With matplotlib it is very easy to add labels, a title and a legend. You can also change the limits of the plot, the style of the lines and much more.\n",
    "\n",
    "The following could be seen as the bare minimum for a plot to be understood as part of reproducible research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, Y, 'r--', linewidth=2)\n",
    "plt.plot(X, Y/2, 'b-', linewidth=2)\n",
    "plt.xlabel('X axis')\n",
    "plt.ylabel('Y axis')\n",
    "plt.title('Plot Title')\n",
    "plt.xlim(-4, 4)\n",
    "plt.ylim(-1.2, 1.2)\n",
    "plt.legend(['red curve', 'blue curve'], loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the documentation pages of Matplotlib [http://matplotlib.org/contents.html](http://matplotlib.org/contents.html) to find all the possible options for a plot and also to see more tutorials, videos and book chapters to help you along the way.\n",
    "\n",
    "Another nice tutorials:\n",
    "* [http://www.labri.fr/perso/nrougier/teaching/matplotlib/](http://www.labri.fr/perso/nrougier/teaching/matplotlib/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment first shows you how to download csv data from an online source. Then we're exploring a dataset of all the cities in the world and compare cities in The Netherlands to the rest of the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data CSV and Pandas\n",
    "We will work with a database of information about cities around the world:\n",
    "\n",
    "[https://dev.maxmind.com/geoip/geoip2/geolite2/](https://dev.maxmind.com/geoip/geoip2/geolite2/)\n",
    "\n",
    "Working with data structures can be done in many ways in Python. There are the standard Python arrays, lists and tuples. You can also use the arrays in the numpy package which allow you to do heavy math operations efficiently. For data analysis Pandas is often used, because data can be put into so-called dataframes. Dataframes store data with column and row names and can easily be manipulated and plotted. You will learn more about Pandas in the Machine Learning workshops. A short intro can be found here:\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as urllib, zipfile, os\n",
    "\n",
    "url = 'https://github.com/CODAIT/redrock/raw/master/twitter-decahose/src/main/resources/Location/'\n",
    "filename = 'worldcitiespop.txt.gz'\n",
    "datafolder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded = urllib.urlopen(url + filename)\n",
    "buf = downloaded.read()\n",
    "\n",
    "try:\n",
    "    os.mkdir(datafolder)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "with open(datafolder + filename, 'wb') as f:\n",
    "    f.write(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# reading files may cause problems or give errors... Can you explain the use of the encoding parameter?\n",
    "cities = pd.read_csv(datafolder + filename, sep=',', low_memory=False, encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that we might need to specify the encoding into ISO-8859-1 because the data might have been encoded into ISO-8859-1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    "We can take a peek at the data by checking out the final rows of data. Do you see any potential problem with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the final rows of the dataset I see that there's some potential problem from the population, because there's NaN aka missing values in some cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities.sort_values(by='Population', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By sorting the cities on population we immediately see the entries of a few of the largest cities in the world.\n",
    "\n",
    "## Assignment 1a\n",
    "To get an idea of where in the world the cities in the dataset are located, we want to make a scatter plot of the position of all the cities in the dataset.\n",
    "\n",
    "Don't worry about drawing country borders, just plot the locations of the cities.\n",
    "\n",
    "Remember to use all the basic plot elements you need to understand this plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "axis = cities[['Latitude', 'Longitude']]\n",
    "graph_line = cities['City']\n",
    "\n",
    "scaler_axis = StandardScaler().fit(axis)\n",
    "axis = scaler_axis.transform(axis)\n",
    "\n",
    "plt.scatter(axis[:,1], axis[:,0], edgecolors='k')\n",
    "\n",
    "## Your code and explanation in comments..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to see the location of the city in the world I make a scatterplot by using the longitude and latitude as an axis, and the city as a dots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1b\n",
    "\n",
    "Now we want to plot the cities in The Netherlands only. Use a scatter plot again to plot the cities, but now vary the size of the marker and the color with the population of that city.\n",
    "\n",
    "Use a colorbar to show how the color of the marker relates to its population.\n",
    "\n",
    "Use sensible limits to your axes so that you show only mainland The Netherlands (and not the Dutch Antilles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_cities = cities[ cities['Country'] =='nl' ]\n",
    "\n",
    "plt.figure(figsize=[7,7]);\n",
    "\n",
    "axis = dutch_cities[['Latitude', 'Longitude']]\n",
    "graph_line = dutch_cities['City']\n",
    "size=dutch_cities['Population']\n",
    "\n",
    "small_size = size / 1000\n",
    "\n",
    "plt.scatter(dutch_cities['Longitude'],dutch_cities['Latitude'],s=small_size, c=size ,edgecolors='k')\n",
    "\n",
    "plt.colorbar(label='Size of Netherlands city');\n",
    "\n",
    "## Your code and explanation in comments...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this scatterplot I use the axis only from city in The Netherlands, and to make the variation of the size I use the population in each city. But because of the population in the big city is so huge it's cover the entire plot, the way to make it readable by dividing the real size by 1000.\n",
    "For the coloring the dots I use the actual size, so the color bar can give us the correct information of the size of the cities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1c\n",
    "\n",
    "Using assignment B, we could clearly see larger cities such as Amsterdam, Rotterdam and even Eindhoven. But we still do not really have a clear overview of how many big cities there are. To show a distribution we use a histogram plot.\n",
    "\n",
    "What happens if we do not call the .dropna() function?\n",
    "\n",
    "Add proper basic plot elements to this plot and try to annotate which data point is Amsterdam and Eindhoven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dutch_cities.dropna().head(5)\n",
    "\n",
    "Amsterdam = dutch_cities[dutch_cities['AccentCity'] =='Amsterdam']\n",
    "\n",
    "Eindhoven = dutch_cities[dutch_cities['AccentCity'] =='Eindhoven']\n",
    "\n",
    "plt.figure();\n",
    "\n",
    "plt.annotate('Amsterdam',(Amsterdam['Population'],1),xytext=(0.8, 0.55), textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            horizontalalignment='right', verticalalignment='top')\n",
    "\n",
    "\n",
    "plt.annotate('Eindhoven',(Eindhoven['Population'],1),xytext=(0.5, 0.55), textcoords='axes fraction',\n",
    "            arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "            horizontalalignment='right', verticalalignment='top')\n",
    "\n",
    "\n",
    "        \n",
    "plt.hist(np.asarray(dutch_cities.dropna().Population), 100,label='ss');\n",
    "\n",
    "\n",
    "plt.xlabel(\"Population\")\n",
    "plt.title(\"Dutch City Population\")\n",
    "\n",
    "# Your code and explanation in comments...\n",
    "# Without dropna we would have null values. Dropna removes null values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this histogram plot I'm trying to show where exactly are amsterdam and eindhoven. I filter the city by name and put the annotate to the specific bar where the city is. As we can see from the plot, Eindhoven has around 200000 population and amsterdam has much bigger population which is more than 700000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1d\n",
    "\n",
    "Now we want to compare how the distribution of Dutch cities compares to that of the entire world.\n",
    "\n",
    "Use subplots to show the dutch distribution (top plot) and the world distribution (bottom plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the subplot of the world cities below this Dutch one\n",
    "\n",
    "plt.figure(figsize=[20, 8]);\n",
    "plt.subplot(2,1,1);\n",
    "\n",
    "plt.hist(dutch_cities.dropna().Population/2500, bins=np.arange(0, 300, 1), density=10,alpha=0.5,color = 'red',label = 'Dutch cities');\n",
    "plt.hist(cities.dropna().Population/2500, bins=np.arange(0, 300, 1), density=10,alpha=0.5,label = 'World cities');\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Your code and explanation in comments...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1e\n",
    "\n",
    "Write what conclusions you can deduce from the above plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see in the histogram plot that dutch cities have more densely populated cities compared to the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*week 2 exercise - part 2*\n",
    "\n",
    "# Data visualization: Two additional Chart Types for Exploring\n",
    "\n",
    "This assignment first shows two useful chart types: parallel coordinates and scatter matrix. You will practice these plots using a new dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Coordinates with Pandas\n",
    "\n",
    "First, we import the required libraries, using standard conventions. For the example of parallel coordinates we shall use the famous iris data set, describing the sepal and petal dimensions for three types of irises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', sep=',', low_memory=False, encoding = 'ISO-8859-1', header=None)\n",
    "iris.columns = ['sepal width','sepal length','petal width','petal length', 'name']\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do not use matplotlib directly but use a plot function of the pandas library that uses matplotlib in the background. In this case we create a parallel coordinates plot.\n",
    "\n",
    "Pandas has many plotting function as can be seen here: http://pandas.pydata.org/pandas-docs/stable/visualization.html#parallel-coordinates\n",
    "\n",
    "The parallel coordinates plot can give insight into a dataset with a large number of features. For the iris set there are four features (petal width, petal length, sepal width, sepal length).\n",
    "\n",
    "While you can make a scatter plot with 4 features using x,y,color and size; a parallel coordinates plot is usually easier to understand once you know how to read it. Here would be the scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.scatter(iris['petal width'], iris['petal length'], c=iris['sepal width'], s=iris['sepal length']**4)\n",
    "plt.xlabel('petal width [cm]')\n",
    "plt.ylabel('petal height [cm]')\n",
    "plt.colorbar(label='sepal width [cm]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import parallel_coordinates\n",
    "%matplotlib inline \n",
    "\n",
    "fig = plt.figure(figsize=[15,6])\n",
    "ax = parallel_coordinates(iris,'name')\n",
    "ax.set_ylabel('width/length [cm]');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter Matrix with Pandas\n",
    "\n",
    "A scatter matrix is a chart that gives you an overview of the correlations between any number of feaures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(iris, alpha=1, figsize=(12, 12), diagonal='kde');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or see what happens if we use the Seaborn library...\n",
    "import seaborn as sns\n",
    "sns.pairplot(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn provides some simples ways to explore the data and correlations in more (visual) detail...\n",
    "import seaborn as sns\n",
    "sns.pairplot(iris, hue=\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "Now try to create similar plots for a new dataset about car features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data file is quite nasty with several different delimeters that read_csv cannot handle very well\n",
    "names=['mpg','cylinders','displacement','horsepower','weight','acceleration','model year','origin','car name','j','k','l','m','n']\n",
    "cars = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data', delimiter=r\"\\s+\", names=names, header=None, engine='python')\n",
    "# Create a subset of dataset with all useful features\n",
    "\n",
    "car_model = cars.iloc[:,[6]]\n",
    "\n",
    "cars = cars.iloc[:,[0,1,2,4,5,7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head(10)\n",
    "## Create the parallel coordinates plot here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a normalized dataset\n",
    "using Mean normalization (see: https://en.wikipedia.org/wiki/Feature_scaling#Mean_normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extend this code to create adinates plot. What happens when you do not use the normalized data? normalized set\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_iris = StandardScaler().fit(cars)\n",
    "cars_norm = scaler_iris.transform(cars)\n",
    "\n",
    "cars_norm['Model Year'] = car_model\n",
    "cars_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a parallel coordinates plot. What happens when you do not use the normalized data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not normalize the data the big values of weight and displacement take over the plot and we cannot read it. If we normalize the data then we can actually get useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,6])\n",
    "ax = parallel_coordinates(cars_norm,'Model Year')\n",
    "ax.set_ylabel('Scale');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[15,6])\n",
    "\n",
    "cars['model year'] = car_model\n",
    "ax = parallel_coordinates(cars,'model year')\n",
    "ax.set_ylabel('Scale');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer this question: What conclusions can you make from the relation between weight and acceleration? If you don't understand how to interpret parallel coordinates plots, read: https://eagereyes.org/techniques/parallel-coordinates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer here in Markdown\n",
    "We can see from the normalized plot that if a car has less weight i will have a higher acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next, try to highlight the model years >= 80. \n",
    "\n",
    "Hints: \n",
    "* you can slice your data with ```cars_norm[cars['model year']>=80]```.\n",
    "* you can plot both all data and the sliced data on top of each other with different colors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the parallel coordinates plot here\n",
    "fig = plt.figure(figsize=[15,6])\n",
    "cars_normYear = cars_norm[cars['model year']>=80]\n",
    "ax = parallel_coordinates(cars_normYear,'Model Year')\n",
    "ax.set_ylabel('Scale');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer this question: what conclusions can you draw from cars with model years 80-82?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers here in Markdown\n",
    "We can see that typically cars from the year 81 have more cylinders compared to 82 and 80. We can see that cars from the 80's have a high mpg, cars from the 82 vary in mpg and cars from the 81's have a relatively the same mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a scatter matrix for the car data. \n",
    "Do we need to use the normalized data?\n",
    "Are we looking for a dataset that we can easily cluster or will we get more luck looking for trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the scatter matrix here\n",
    "import seaborn as sns\n",
    "cars['model year'] = car_model\n",
    "sns.pairplot(cars, hue=\"model year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is no need to normalize the data with a scatter matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(cars_norm, hue=\"Model Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What are your final conclusions looking at the (visual) results? What did you learn about the data and dataset? Or what new questions did you derive from the plots you've made?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we can see that in time cars become lighter / faster, burn less fuel and were made with less cylinders and with less displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
